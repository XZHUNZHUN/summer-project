{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pre-trained model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7nzdpE-26OH",
        "colab_type": "text"
      },
      "source": [
        "# **Generating audio from my pre-trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ost7XmPp3VQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import autograd\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pickle as pk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "42re1HmEy1n2"
      },
      "source": [
        "## **generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rhd_Iw4ry1n3",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, model_size=64, num_channels=1, latent_dim=100,\n",
        "                 post_proc_filt_len=512):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model_size = model_size # d\n",
        "        self.num_channels = num_channels # c\n",
        "        self.latent_dim = latent_dim\n",
        "        self.post_proc_filt_len = post_proc_filt_len\n",
        "        \n",
        "        self.fc1 = nn.DataParallel(nn.Linear(latent_dim, 256 * model_size))\n",
        "        \n",
        "        self.tconv1 = None\n",
        "        self.tconv2 = None\n",
        "        self.tconv3 = None\n",
        "        self.tconv4 = None\n",
        "        self.tconv5 = None\n",
        "        \n",
        "\n",
        "        self.tconv1 = nn.DataParallel(\n",
        "                 nn.ConvTranspose1d(16 * model_size, 8 * model_size, 25, stride=4, padding=11,\n",
        "                                    output_padding=1))\n",
        "        self.tconv2 = nn.DataParallel(\n",
        "                 nn.ConvTranspose1d(8 * model_size, 4 * model_size, 25, stride=4, padding=11,\n",
        "                                    output_padding=1))\n",
        "        self.tconv3 = nn.DataParallel(\n",
        "                 nn.ConvTranspose1d(4 * model_size, 2 * model_size, 25, stride=4, padding=11,\n",
        "                                    output_padding=1))\n",
        "        self.tconv4 = nn.DataParallel(\n",
        "                 nn.ConvTranspose1d(2 * model_size, model_size, 25, stride=4, padding=11,\n",
        "                                    output_padding=1))\n",
        "        self.tconv5 = nn.DataParallel(\n",
        "                 nn.ConvTranspose1d(model_size, num_channels, 25, stride=4, padding=11,\n",
        "                                    output_padding=1))\n",
        "\n",
        "        \n",
        "        if post_proc_filt_len:\n",
        "            self.ppfilter1 = nn.DataParallel(nn.Conv1d(num_channels, num_channels, post_proc_filt_len))\n",
        "        \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.ConvTranspose1d) or isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.fc1(x).view(-1, 16 * self.model_size, 16)\n",
        "        x = F.relu(x)\n",
        "        output = None\n",
        "        \n",
        "        x = F.relu(self.tconv1(x))\n",
        "        x = F.relu(self.tconv2(x))\n",
        "        x = F.relu(self.tconv3(x))\n",
        "        x = F.relu(self.tconv4(x))\n",
        "        output = torch.tanh(self.tconv5(x))\n",
        "                    \n",
        "        if self.post_proc_filt_len:\n",
        "            # Pad for \"same\" filtering\n",
        "            if (self.post_proc_filt_len % 2) == 0:\n",
        "                pad_left = self.post_proc_filt_len // 2\n",
        "                pad_right = pad_left - 1\n",
        "            else:\n",
        "                pad_left = (self.post_proc_filt_len - 1) // 2\n",
        "                pad_right = pad_left\n",
        "            output = self.ppfilter1(F.pad(output, (pad_left, pad_right)))\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0F19Fa9Xy1n8"
      },
      "source": [
        "## **save model and save audio**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fcHAyLJzy1n9",
        "colab": {}
      },
      "source": [
        "\n",
        "def save_sample(data,sample_size,save_path):\n",
        "  for i in range(sample_size):\n",
        "    sample = data[i].reshape(16384,1)    \n",
        "    \n",
        "    librosa.output.write_wav(save_path+'{}.wav'.format(i),sample, 16000)\n",
        "\n",
        "def showing_wave(data):\n",
        "  sample = data.reshape(16384)\n",
        "  print(sample)\n",
        "  plt.figure(figsize=(25,8))\n",
        "  librosa.display.waveplot(sample,16000)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wzT4Qdh3oxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__==\"__main__\":\n",
        " \n",
        "    laten_dim = 100\n",
        "    sample_size = 2  \n",
        "    load_model = True\n",
        "    G = Generator()\n",
        "    \n",
        "    #try to change the path\n",
        "    file_path = './drive/My Drive/bird1.pkl'\n",
        "    save_path = './home/'\n",
        "    #load the parameter of network \n",
        "    \n",
        "    print('loading model...')\n",
        "      \n",
        "    \n",
        "    G.load_state_dict(torch.load(file_path,map_location='cpu')) \n",
        "  \n",
        "    \n",
        "    #========= test generator ==============#\n",
        "    #sample noise\n",
        "    sample_noise = torch.randn(sample_size, laten_dim) \n",
        "    sample_output = G(sample_noise)\n",
        "    for j in range(sample_size):\n",
        "      showing_wave(sample_output.data.numpy()[j])\n",
        "    save_sample(sample_output.data.numpy(),sample_size,save_path)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}